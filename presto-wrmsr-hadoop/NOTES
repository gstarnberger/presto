https://docs.aws.amazon.com/ElasticMapReduce/latest/ManagementGuide/emr-web-interfaces.html

do emr yarn
https://github.com/prestodb/presto-yarn
hi

https://hadoop.apache.org/docs/r1.2.1/cluster_setup.html

org.apache.hadoop.hive.conf.HiveConf.ConfVars.*


look at java_sort_ranger

https://docs.aws.amazon.com/ElasticMapReduce/latest/ManagementGuide/making_api_requests.html


https://aws.amazon.com/elasticmapreduce/faqs/
https://pythonhosted.org/mrjob/guides/emr-opts.html
https://docs.aws.amazon.com/ElasticMapReduce/latest/ManagementGuide/emr-overview-arch.html
https://docs.aws.amazon.com/ElasticMapReduce/latest/ManagementGuide/emr-web-interfaces.html

https://mrjob.readthedocs.org/en/latest/guides/emr-advanced.html
https://github.com/Yelp/mrjob/blob/master/mrjob/emr.py#L2042

https://wiki.apache.org/hadoop/HadoopStreaming


https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/filecache/DistributedCache.html


<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://myhost/metastore</value>
  <description>the URL of the MySQL database</description>
</property>

<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>com.mysql.jdbc.Driver</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>hive</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>mypassword</value>
</property>

<property>
  <name>datanucleus.autoCreateSchema</name>
  <value>false</value>
</property>

<property>
  <name>datanucleus.fixedDatastore</name>
  <value>true</value>
</property>

<property>
  <name>hive.metastore.uris</name>
  <value>thrift://<n.n.n.n>:9083</value>
  <description>IP address (or fully-qualified domain name) and port of the metastore host</description>
</property>




<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:postgresql://myhost/metastore</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>org.postgresql.Driver</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>hiveuser</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>mypassword</value>
</property>

<property>
  <name>datanucleus.autoCreateSchema</name>
  <value>false</value>
</property>

<property>
  <name>hive.metastore.uris</name>
  <value>thrift://<n.n.n.n>:9083</value>
  <description>IP address (or fully-qualified domain name) and port of the metastore host</description>
</property>





<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:oracle:thin:@//myhost/xe</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>oracle.jdbc.OracleDriver</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>hiveuser</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>mypassword</value>
</property>

<property>
  <name>datanucleus.autoCreateSchema</name>
  <value>false</value>
</property>

<property>
  <name>datanucleus.fixedDatastore</name>
  <value>true</value>
</property>

<property>
  <name>hive.metastore.uris</name>
  <value>thrift://<n.n.n.n>:9083</value>
  <description>IP address (or fully-qualified domain name) and port of the metastore host</description>
</property>









METASTOREWAREHOUSE = new HiveConf.ConfVars("METASTOREWAREHOUSE", 65, "hive.metastore.warehouse.dir", "/user/hive/warehouse", "location of default database for the warehouse");
METASTOREURIS = new HiveConf.ConfVars("METASTOREURIS", 66, "hive.metastore.uris", "", "Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.");
METASTORETHRIFTCONNECTIONRETRIES = new HiveConf.ConfVars("METASTORETHRIFTCONNECTIONRETRIES", 67, "hive.metastore.connect.retries", Integer.valueOf(3), "Number of retries while opening a connection to metastore");
METASTORETHRIFTFAILURERETRIES = new HiveConf.ConfVars("METASTORETHRIFTFAILURERETRIES", 68, "hive.metastore.failure.retries", Integer.valueOf(1), "Number of retries upon failure of Thrift metastore calls");
METASTORE_CLIENT_CONNECT_RETRY_DELAY = new HiveConf.ConfVars("METASTORE_CLIENT_CONNECT_RETRY_DELAY", 69, "hive.metastore.client.connect.retry.delay", "1s", new TimeValidator(TimeUnit.SECONDS), "Number of seconds for the client to wait between consecutive connection attempts");
METASTORE_CLIENT_SOCKET_TIMEOUT = new HiveConf.ConfVars("METASTORE_CLIENT_SOCKET_TIMEOUT", 70, "hive.metastore.client.socket.timeout", "600s", new TimeValidator(TimeUnit.SECONDS), "MetaStore Client socket timeout in seconds");
METASTORE_CLIENT_SOCKET_LIFETIME = new HiveConf.ConfVars("METASTORE_CLIENT_SOCKET_LIFETIME", 71, "hive.metastore.client.socket.lifetime", "0s", new TimeValidator(TimeUnit.SECONDS), "MetaStore Client socket lifetime in seconds. After this time is exceeded, client\nreconnects on the next MetaStore operation. A value of 0s means the connection\nhas an infinite lifetime.");
METASTOREPWD = new HiveConf.ConfVars("METASTOREPWD", 72, "javax.jdo.option.ConnectionPassword", "mine", "password to use against metastore database");
METASTORECONNECTURLHOOK = new HiveConf.ConfVars("METASTORECONNECTURLHOOK", 73, "hive.metastore.ds.connection.url.hook", "", "Name of the hook to use for retrieving the JDO connection URL. If empty, the value in javax.jdo.option.ConnectionURL is used");
METASTOREMULTITHREADED = new HiveConf.ConfVars("METASTOREMULTITHREADED", 74, "javax.jdo.option.Multithreaded", Boolean.valueOf(true), "Set this to true if multiple threads access metastore through JDO concurrently.");
METASTORECONNECTURLKEY = new HiveConf.ConfVars("METASTORECONNECTURLKEY", 75, "javax.jdo.option.ConnectionURL", "jdbc:derby:;databaseName=metastore_db;create=true", "JDBC connect string for a JDBC metastore");
METASTORESERVERMAXMESSAGESIZE = new HiveConf.ConfVars("METASTORESERVERMAXMESSAGESIZE", 79, "hive.metastore.server.max.message.size", Integer.valueOf(104857600), "Maximum message size in bytes a HMS will accept.");
METASTORESERVERMINTHREADS = new HiveConf.ConfVars("METASTORESERVERMINTHREADS", 80, "hive.metastore.server.min.threads", Integer.valueOf(200), "Minimum number of worker threads in the Thrift server\'s pool.");
METASTORESERVERMAXTHREADS = new HiveConf.ConfVars("METASTORESERVERMAXTHREADS", 81, "hive.metastore.server.max.threads", Integer.valueOf(1000), "Maximum number of worker threads in the Thrift server\'s pool.");
METASTORE_TCP_KEEP_ALIVE = new HiveConf.ConfVars("METASTORE_TCP_KEEP_ALIVE", 82, "hive.metastore.server.tcp.keepalive", Boolean.valueOf(true), "Whether to enable TCP keepalive for the metastore server. Keepalive will prevent accumulation of half-open connections.");
METASTORE_INT_ORIGINAL = new HiveConf.ConfVars("METASTORE_INT_ORIGINAL", 83, "hive.metastore.archive.intermediate.original", "_INTERMEDIATE_ORIGINAL", "Intermediate dir suffixes used for archiving. Not important what they\nare, as long as collisions are avoided");
METASTORE_INT_ARCHIVED = new HiveConf.ConfVars("METASTORE_INT_ARCHIVED", 84, "hive.metastore.archive.intermediate.archived", "_INTERMEDIATE_ARCHIVED", "");
METASTORE_INT_EXTRACTED = new HiveConf.ConfVars("METASTORE_INT_EXTRACTED", 85, "hive.metastore.archive.intermediate.extracted", "_INTERMEDIATE_EXTRACTED", "");
METASTORE_KERBEROS_KEYTAB_FILE = new HiveConf.ConfVars("METASTORE_KERBEROS_KEYTAB_FILE", 86, "hive.metastore.kerberos.keytab.file", "", "The path to the Kerberos Keytab file containing the metastore Thrift server\'s service principal.");
METASTORE_KERBEROS_PRINCIPAL = new HiveConf.ConfVars("METASTORE_KERBEROS_PRINCIPAL", 87, "hive.metastore.kerberos.principal", "hive-metastore/_HOST@EXAMPLE.COM", "The service principal for the metastore Thrift server. \nThe special string _HOST will be replaced automatically with the correct host name.");
METASTORE_USE_THRIFT_SASL = new HiveConf.ConfVars("METASTORE_USE_THRIFT_SASL", 88, "hive.metastore.sasl.enabled", Boolean.valueOf(false), "If true, the metastore Thrift interface will be secured with SASL. Clients must authenticate with Kerberos.");
METASTORE_USE_THRIFT_FRAMED_TRANSPORT = new HiveConf.ConfVars("METASTORE_USE_THRIFT_FRAMED_TRANSPORT", 89, "hive.metastore.thrift.framed.transport.enabled", Boolean.valueOf(false), "If true, the metastore Thrift interface will use TFramedTransport. When false (default) a standard TTransport is used.");
METASTORE_USE_THRIFT_COMPACT_PROTOCOL = new HiveConf.ConfVars("METASTORE_USE_THRIFT_COMPACT_PROTOCOL", 90, "hive.metastore.thrift.compact.protocol.enabled", Boolean.valueOf(false), "If true, the metastore Thrift interface will use TCompactProtocol. When false (default) TBinaryProtocol will be used.\nSetting it to true will break compatibility with older clients running TBinaryProtocol.");
METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_CLS = new HiveConf.ConfVars("METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_CLS", 91, "hive.cluster.delegation.token.store.class", "org.apache.hadoop.hive.thrift.MemoryTokenStore", "The delegation token store implementation. Set to org.apache.hadoop.hive.thrift.ZooKeeperTokenStore for load-balanced cluster.");
METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_CONNECTSTR = new HiveConf.ConfVars("METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_CONNECTSTR", 92, "hive.cluster.delegation.token.store.zookeeper.connectString", "", "The ZooKeeper token store connect string. You can re-use the configuration value\nset in hive.zookeeper.quorum, by leaving this parameter unset.");
METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_ZNODE = new HiveConf.ConfVars("METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_ZNODE", 93, "hive.cluster.delegation.token.store.zookeeper.znode", "/hivedelegation", "The root path for token store data. Note that this is used by both HiveServer2 and\nMetaStore to store delegation Token. One directory gets created for each of them.\nThe final directory names would have the servername appended to it (HIVESERVER2,\nMETASTORE).");
METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_ACL = new HiveConf.ConfVars("METASTORE_CLUSTER_DELEGATION_TOKEN_STORE_ZK_ACL", 94, "hive.cluster.delegation.token.store.zookeeper.acl", "", "ACL for token store entries. Comma separated list of ACL entries. For example:\nsasl:hive/host1@MY.DOMAIN:cdrwa,sasl:hive/host2@MY.DOMAIN:cdrwa\nDefaults to all permissions for the hiveserver2/metastore process user.");
METASTORE_CACHE_PINOBJTYPES = new HiveConf.ConfVars("METASTORE_CACHE_PINOBJTYPES", 95, "hive.metastore.cache.pinobjtypes", "Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order", "List of comma separated metastore object types that should be pinned in the cache");
METASTORE_CONNECTION_POOLING_TYPE = new HiveConf.ConfVars("METASTORE_CONNECTION_POOLING_TYPE", 96, "datanucleus.connectionPoolingType", "BONECP", "Specify connection pool library for datanucleus");
METASTORE_VALIDATE_TABLES = new HiveConf.ConfVars("METASTORE_VALIDATE_TABLES", 97, "datanucleus.validateTables", Boolean.valueOf(false), "validates existing schema against code. turn this on if you want to verify existing schema");
METASTORE_VALIDATE_COLUMNS = new HiveConf.ConfVars("METASTORE_VALIDATE_COLUMNS", 98, "datanucleus.validateColumns", Boolean.valueOf(false), "validates existing schema against code. turn this on if you want to verify existing schema");
METASTORE_VALIDATE_CONSTRAINTS = new HiveConf.ConfVars("METASTORE_VALIDATE_CONSTRAINTS", 99, "datanucleus.validateConstraints", Boolean.valueOf(false), "validates existing schema against code. turn this on if you want to verify existing schema");
METASTORE_STORE_MANAGER_TYPE = new HiveConf.ConfVars("METASTORE_STORE_MANAGER_TYPE", 100, "datanucleus.storeManagerType", "rdbms", "metadata store type");
METASTORE_AUTO_CREATE_SCHEMA = new HiveConf.ConfVars("METASTORE_AUTO_CREATE_SCHEMA", 101, "datanucleus.autoCreateSchema", Boolean.valueOf(true), "creates necessary schema on a startup if one doesn\'t exist. set this to false, after creating it once");
METASTORE_FIXED_DATASTORE = new HiveConf.ConfVars("METASTORE_FIXED_DATASTORE", 102, "datanucleus.fixedDatastore", Boolean.valueOf(false), "");
METASTORE_SCHEMA_VERIFICATION = new HiveConf.ConfVars("METASTORE_SCHEMA_VERIFICATION", 103, "hive.metastore.schema.verification", Boolean.valueOf(false), "Enforce metastore schema version consistency.\nTrue: Verify that version information stored in metastore matches with one from Hive jars.  Also disable automatic\n      schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures\n      proper metastore schema migration. (Default)\nFalse: Warn if the version information stored in metastore doesn\'t match with one from in Hive jars.");
METASTORE_SCHEMA_VERIFICATION_RECORD_VERSION = new HiveConf.ConfVars("METASTORE_SCHEMA_VERIFICATION_RECORD_VERSION", 104, "hive.metastore.schema.verification.record.version", Boolean.valueOf(true), "When true the current MS version is recorded in the VERSION table. If this is disabled and verification is\n enabled the MS will be unusable.");
METASTORE_AUTO_START_MECHANISM_MODE = new HiveConf.ConfVars("METASTORE_AUTO_START_MECHANISM_MODE", 105, "datanucleus.autoStartMechanismMode", "checked", "throw exception if metadata tables are incorrect");
METASTORE_TRANSACTION_ISOLATION = new HiveConf.ConfVars("METASTORE_TRANSACTION_ISOLATION", 106, "datanucleus.transactionIsolation", "read-committed", "Default transaction isolation level for identity generation.");
METASTORE_CACHE_LEVEL2 = new HiveConf.ConfVars("METASTORE_CACHE_LEVEL2", 107, "datanucleus.cache.level2", Boolean.valueOf(false), "Use a level 2 cache. Turn this off if metadata is changed independently of Hive metastore server");
METASTORE_CACHE_LEVEL2_TYPE = new HiveConf.ConfVars("METASTORE_CACHE_LEVEL2_TYPE", 108, "datanucleus.cache.level2.type", "none", "");
METASTORE_IDENTIFIER_FACTORY = new HiveConf.ConfVars("METASTORE_IDENTIFIER_FACTORY", 109, "datanucleus.identifierFactory", "datanucleus1", "Name of the identifier factory to use when generating table/column names etc. \n\'datanucleus1\' is used for backward compatibility with DataNucleus v1");
METASTORE_USE_LEGACY_VALUE_STRATEGY = new HiveConf.ConfVars("METASTORE_USE_LEGACY_VALUE_STRATEGY", 110, "datanucleus.rdbms.useLegacyNativeValueStrategy", Boolean.valueOf(true), "");
METASTORE_PLUGIN_REGISTRY_BUNDLE_CHECK = new HiveConf.ConfVars("METASTORE_PLUGIN_REGISTRY_BUNDLE_CHECK", 111, "datanucleus.plugin.pluginRegistryBundleCheck", "LOG", "Defines what happens when plugin bundles are found and are duplicated [EXCEPTION|LOG|NONE]");
METASTORE_BATCH_RETRIEVE_MAX = new HiveConf.ConfVars("METASTORE_BATCH_RETRIEVE_MAX", 112, "hive.metastore.batch.retrieve.max", Integer.valueOf(300), "Maximum number of objects (tables/partitions) can be retrieved from metastore in one batch. \nThe higher the number, the less the number of round trips is needed to the Hive metastore server, \nbut it may also cause higher memory requirement at the client side.");
METASTORE_BATCH_RETRIEVE_TABLE_PARTITION_MAX = new HiveConf.ConfVars("METASTORE_BATCH_RETRIEVE_TABLE_PARTITION_MAX", 113, "hive.metastore.batch.retrieve.table.partition.max", Integer.valueOf(1000), "Maximum number of table partitions that metastore internally retrieves in one batch.");
METASTORE_INIT_HOOKS = new HiveConf.ConfVars("METASTORE_INIT_HOOKS", 114, "hive.metastore.init.hooks", "", "A comma separated list of hooks to be invoked at the beginning of HMSHandler initialization. \nAn init hook is specified as the name of Java class which extends org.apache.hadoop.hive.metastore.MetaStoreInitListener.");
METASTORE_PRE_EVENT_LISTENERS = new HiveConf.ConfVars("METASTORE_PRE_EVENT_LISTENERS", 115, "hive.metastore.pre.event.listeners", "", "List of comma separated listeners for metastore events.");
METASTORE_EVENT_LISTENERS = new HiveConf.ConfVars("METASTORE_EVENT_LISTENERS", 116, "hive.metastore.event.listeners", "", "");
METASTORE_EVENT_DB_LISTENER_TTL = new HiveConf.ConfVars("METASTORE_EVENT_DB_LISTENER_TTL", 117, "hive.metastore.event.db.listener.timetolive", "86400s", new TimeValidator(TimeUnit.SECONDS), "time after which events will be removed from the database listener queue");
METASTORE_AUTHORIZATION_STORAGE_AUTH_CHECKS = new HiveConf.ConfVars("METASTORE_AUTHORIZATION_STORAGE_AUTH_CHECKS", 118, "hive.metastore.authorization.storage.checks", Boolean.valueOf(false), "Should the metastore do authorization checks against the underlying storage (usually hdfs) \nfor operations like drop-partition (disallow the drop-partition if the user in\nquestion doesn\'t have permissions to delete the corresponding directory\non the storage).");
METASTORE_EVENT_CLEAN_FREQ = new HiveConf.ConfVars("METASTORE_EVENT_CLEAN_FREQ", 119, "hive.metastore.event.clean.freq", "0s", new TimeValidator(TimeUnit.SECONDS), "Frequency at which timer task runs to purge expired events in metastore.");
METASTORE_EVENT_EXPIRY_DURATION = new HiveConf.ConfVars("METASTORE_EVENT_EXPIRY_DURATION", 120, "hive.metastore.event.expiry.duration", "0s", new TimeValidator(TimeUnit.SECONDS), "Duration after which events expire from events table");
METASTORE_EXECUTE_SET_UGI = new HiveConf.ConfVars("METASTORE_EXECUTE_SET_UGI", 121, "hive.metastore.execute.setugi", Boolean.valueOf(true), "In unsecure mode, setting this property to true will cause the metastore to execute DFS operations using \nthe client\'s reported user and group permissions. Note that this property must be set on \nboth the client and server sides. Further note that its best effort. \nIf client sets its to true and server sets it to false, client setting will be ignored.");
METASTORE_PARTITION_NAME_WHITELIST_PATTERN = new HiveConf.ConfVars("METASTORE_PARTITION_NAME_WHITELIST_PATTERN", 122, "hive.metastore.partition.name.whitelist.pattern", "", "Partition names will be checked against this regex pattern and rejected if not matched.");
METASTORE_INTEGER_JDO_PUSHDOWN = new HiveConf.ConfVars("METASTORE_INTEGER_JDO_PUSHDOWN", 123, "hive.metastore.integral.jdo.pushdown", Boolean.valueOf(false), "Allow JDO query pushdown for integral partition columns in metastore. Off by default. This\nimproves metastore perf for integral columns, especially if there\'s a large number of partitions.\nHowever, it doesn\'t work correctly with integral values that are not normalized (e.g. have\nleading zeroes, like 0012). If metastore direct SQL is enabled and works, this optimization\nis also irrelevant.");
METASTORE_TRY_DIRECT_SQL = new HiveConf.ConfVars("METASTORE_TRY_DIRECT_SQL", 124, "hive.metastore.try.direct.sql", Boolean.valueOf(true), "Whether the Hive metastore should try to use direct SQL queries instead of the\nDataNucleus for certain read paths. This can improve metastore performance when\nfetching many partitions or column statistics by orders of magnitude; however, it\nis not guaranteed to work on all RDBMS-es and all versions. In case of SQL failures,\nthe metastore will fall back to the DataNucleus, so it\'s safe even if SQL doesn\'t\nwork for all queries on your datastore. If all SQL queries fail (for example, your\nmetastore is backed by MongoDB), you might want to disable this to save the\ntry-and-fall-back cost.");
METASTORE_DIRECT_SQL_PARTITION_BATCH_SIZE = new HiveConf.ConfVars("METASTORE_DIRECT_SQL_PARTITION_BATCH_SIZE", 125, "hive.metastore.direct.sql.batch.size", Integer.valueOf(0), "Batch size for partition and other object retrieval from the underlying DB in direct\nSQL. For some DBs like Oracle and MSSQL, there are hardcoded or perf-based limitations\nthat necessitate this. For DBs that can handle the queries, this isn\'t necessary and\nmay impede performance. -1 means no batching, 0 means automatic batching.");
METASTORE_TRY_DIRECT_SQL_DDL = new HiveConf.ConfVars("METASTORE_TRY_DIRECT_SQL_DDL", 126, "hive.metastore.try.direct.sql.ddl", Boolean.valueOf(true), "Same as hive.metastore.try.direct.sql, for read statements within a transaction that\nmodifies metastore data. Due to non-standard behavior in Postgres, if a direct SQL\nselect query has incorrect syntax or something similar inside a transaction, the\nentire transaction will fail and fall-back to DataNucleus will not be possible. You\nshould disable the usage of direct SQL inside transactions if that happens in your case.");
METASTORE_ORM_RETRIEVE_MAPNULLS_AS_EMPTY_STRINGS = new HiveConf.ConfVars("METASTORE_ORM_RETRIEVE_MAPNULLS_AS_EMPTY_STRINGS", 127, "hive.metastore.orm.retrieveMapNullsAsEmptyStrings", Boolean.valueOf(false), "Thrift does not support nulls in maps, so any nulls present in maps retrieved from ORM must either be pruned or converted to empty strings. Some backing dbs such as Oracle persist empty strings as nulls, so we should set this parameter if we wish to reverse that behaviour. For others, pruning is the correct behaviour");
METASTORE_DISALLOW_INCOMPATIBLE_COL_TYPE_CHANGES = new HiveConf.ConfVars("METASTORE_DISALLOW_INCOMPATIBLE_COL_TYPE_CHANGES", 128, "hive.metastore.disallow.incompatible.col.type.changes", Boolean.valueOf(false), "If true (default is false), ALTER TABLE operations which change the type of a\ncolumn (say STRING) to an incompatible type (say MAP) are disallowed.\nRCFile default SerDe (ColumnarSerDe) serializes the values in such a way that the\ndatatypes can be converted from string to any type. The map is also serialized as\na string, which can be read as a string as well. However, with any binary\nserialization, this is not true. Blocking the ALTER TABLE prevents ClassCastExceptions\nwhen subsequently trying to access old partitions.\n\nPrimitive types like INT, STRING, BIGINT, etc., are compatible with each other and are\nnot blocked.\n\nSee HIVE-4409 for more details.");
METASTORE_RAW_STORE_IMPL = new HiveConf.ConfVars("METASTORE_RAW_STORE_IMPL", 131, "hive.metastore.rawstore.impl", "org.apache.hadoop.hive.metastore.ObjectStore", "Name of the class that implements org.apache.hadoop.hive.metastore.rawstore interface. \nThis class is used to store and retrieval of raw metadata objects such as table, database");
METASTORE_CONNECTION_DRIVER = new HiveConf.ConfVars("METASTORE_CONNECTION_DRIVER", 132, "javax.jdo.option.ConnectionDriverName", "org.apache.derby.jdbc.EmbeddedDriver", "Driver class name for a JDBC metastore");
METASTORE_MANAGER_FACTORY_CLASS = new HiveConf.ConfVars("METASTORE_MANAGER_FACTORY_CLASS", 133, "javax.jdo.PersistenceManagerFactoryClass", "org.datanucleus.api.jdo.JDOPersistenceManagerFactory", "class implementing the jdo persistence");
METASTORE_EXPRESSION_PROXY_CLASS = new HiveConf.ConfVars("METASTORE_EXPRESSION_PROXY_CLASS", 134, "hive.metastore.expression.proxy", "org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore", "");
METASTORE_DETACH_ALL_ON_COMMIT = new HiveConf.ConfVars("METASTORE_DETACH_ALL_ON_COMMIT", 135, "javax.jdo.option.DetachAllOnCommit", Boolean.valueOf(true), "Detaches all objects from session so that they can be used after transaction is committed");
METASTORE_NON_TRANSACTIONAL_READ = new HiveConf.ConfVars("METASTORE_NON_TRANSACTIONAL_READ", 136, "javax.jdo.option.NonTransactionalRead", Boolean.valueOf(true), "Reads outside of transactions");
METASTORE_CONNECTION_USER_NAME = new HiveConf.ConfVars("METASTORE_CONNECTION_USER_NAME", 137, "javax.jdo.option.ConnectionUserName", "APP", "Username to use against metastore database");
METASTORE_END_FUNCTION_LISTENERS = new HiveConf.ConfVars("METASTORE_END_FUNCTION_LISTENERS", 138, "hive.metastore.end.function.listeners", "", "List of comma separated listeners for the end of metastore functions.");
METASTORE_PART_INHERIT_TBL_PROPS = new HiveConf.ConfVars("METASTORE_PART_INHERIT_TBL_PROPS", 139, "hive.metastore.partition.inherit.table.properties", "", "List of comma separated keys occurring in table properties which will get inherited to newly created partitions. \n* implies all the keys will get inherited.");
METASTORE_FILTER_HOOK = new HiveConf.ConfVars("METASTORE_FILTER_HOOK", 140, "hive.metastore.filter.hook", "org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl", "Metastore hook class for filtering the metadata read results. If hive.security.authorization.manageris set to instance of HiveAuthorizerFactory, then this value is ignored.");
FIRE_EVENTS_FOR_DML = new HiveConf.ConfVars("FIRE_EVENTS_FOR_DML", 141, "hive.metastore.dml.events", Boolean.valueOf(false), "If true, the metastore will be asked to fire events for DML operations");
METASTORE_CLIENT_DROP_PARTITIONS_WITH_EXPRESSIONS = new HiveConf.ConfVars("METASTORE_CLIENT_DROP_PARTITIONS_WITH_EXPRESSIONS", 142, "hive.metastore.client.drop.partitions.using.expressions", Boolean.valueOf(true), "Choose whether dropping partitions with HCatClient pushes the partition-predicate to the metastore, or drops partitions iteratively");
METASTORE_AGGREGATE_STATS_CACHE_ENABLED = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_ENABLED", 143, "hive.metastore.aggregate.stats.cache.enabled", Boolean.valueOf(true), "Whether aggregate stats caching is enabled or not.");
METASTORE_AGGREGATE_STATS_CACHE_SIZE = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_SIZE", 144, "hive.metastore.aggregate.stats.cache.size", Integer.valueOf(10000), "Maximum number of aggregate stats nodes that we will place in the metastore aggregate stats cache.");
METASTORE_AGGREGATE_STATS_CACHE_MAX_PARTITIONS = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_MAX_PARTITIONS", 145, "hive.metastore.aggregate.stats.cache.max.partitions", Integer.valueOf(10000), "Maximum number of partitions that are aggregated per cache node.");
METASTORE_AGGREGATE_STATS_CACHE_FPP = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_FPP", 146, "hive.metastore.aggregate.stats.cache.fpp", Float.valueOf(0.01F), "Maximum false positive probability for the Bloom Filter used in each aggregate stats cache node (default 1%).");
METASTORE_AGGREGATE_STATS_CACHE_MAX_VARIANCE = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_MAX_VARIANCE", 147, "hive.metastore.aggregate.stats.cache.max.variance", Float.valueOf(0.01F), "Maximum tolerable variance in number of partitions between a cached node and our request (default 1%).");
METASTORE_AGGREGATE_STATS_CACHE_TTL = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_TTL", 148, "hive.metastore.aggregate.stats.cache.ttl", "600s", new TimeValidator(TimeUnit.SECONDS), "Number of seconds for a cached node to be active in the cache before they become stale.");
METASTORE_AGGREGATE_STATS_CACHE_MAX_WRITER_WAIT = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_MAX_WRITER_WAIT", 149, "hive.metastore.aggregate.stats.cache.max.writer.wait", "5000ms", new TimeValidator(TimeUnit.MILLISECONDS), "Number of milliseconds a writer will wait to acquire the writelock before giving up.");
METASTORE_AGGREGATE_STATS_CACHE_MAX_READER_WAIT = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_MAX_READER_WAIT", 150, "hive.metastore.aggregate.stats.cache.max.reader.wait", "1000ms", new TimeValidator(TimeUnit.MILLISECONDS), "Number of milliseconds a reader will wait to acquire the readlock before giving up.");
METASTORE_AGGREGATE_STATS_CACHE_MAX_FULL = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_MAX_FULL", 151, "hive.metastore.aggregate.stats.cache.max.full", Float.valueOf(0.9F), "Maximum cache full % after which the cache cleaner thread kicks in.");
METASTORE_AGGREGATE_STATS_CACHE_CLEAN_UNTIL = new HiveConf.ConfVars("METASTORE_AGGREGATE_STATS_CACHE_CLEAN_UNTIL", 152, "hive.metastore.aggregate.stats.cache.clean.until", Float.valueOf(0.8F), "The cleaner thread cleans until cache reaches this % full size.");
METADATA_EXPORT_LOCATION = new HiveConf.ConfVars("METADATA_EXPORT_LOCATION", 153, "hive.metadata.export.location", "", "When used in conjunction with the org.apache.hadoop.hive.ql.parse.MetaDataExportListener pre event listener, \nit is the location to which the metadata will be exported. The default is an empty string, which results in the \nmetadata being exported to the current user\'s home directory on HDFS.");
HIVE_METASTORE_FS_HANDLER_CLS = new HiveConf.ConfVars("HIVE_METASTORE_FS_HANDLER_CLS", 159, "hive.metastore.fs.handler.class", "org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl", "");
SERDESUSINGMETASTOREFORSCHEMA = new HiveConf.ConfVars("SERDESUSINGMETASTOREFORSCHEMA", 219, "hive.serdes.using.metastore.for.schema", "org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe", "SerDes retriving schema from metastore. This an internal parameter. Check with the hive dev. team");
HIVEMETADATAONLYQUERIES = new HiveConf.ConfVars("HIVEMETADATAONLYQUERIES", 325, "hive.optimize.metadataonly", Boolean.valueOf(true), "");
HIVE_METASTORE_STATS_NDV_DENSITY_FUNCTION = new HiveConf.ConfVars("HIVE_METASTORE_STATS_NDV_DENSITY_FUNCTION", 365, "hive.metastore.stats.ndv.densityfunction", Boolean.valueOf(false), "Whether to use density function to estimate the NDV for the whole table based on the NDV of partitions");
HIVEOPTIMIZEMETADATAQUERIES = new HiveConf.ConfVars("HIVEOPTIMIZEMETADATAQUERIES", 410, "hive.compute.query.using.stats", Boolean.valueOf(false), "When set to true Hive will answer a few queries like count(1) purely using stats\nstored in metastore. For basic stats collection turn on the config hive.stats.autogather to true.\nFor more advanced stats collection need to run analyze table queries.");
HIVE_METASTORE_AUTHORIZATION_MANAGER = new HiveConf.ConfVars("HIVE_METASTORE_AUTHORIZATION_MANAGER", 421, "hive.security.metastore.authorization.manager", "org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider", "Names of authorization manager classes (comma separated) to be used in the metastore\nfor authorization. The user defined authorization class should implement interface\norg.apache.hadoop.hive.ql.security.authorization.HiveMetastoreAuthorizationProvider.\nAll authorization manager classes have to successfully authorize the metastore API\ncall for the command execution to be allowed.");
HIVE_METASTORE_AUTHORIZATION_AUTH_READS = new HiveConf.ConfVars("HIVE_METASTORE_AUTHORIZATION_AUTH_READS", 422, "hive.security.metastore.authorization.auth.reads", Boolean.valueOf(true), "If this is true, metastore authorizer authorizes read actions on database, table");
HIVE_METASTORE_AUTHENTICATOR_MANAGER = new HiveConf.ConfVars("HIVE_METASTORE_AUTHENTICATOR_MANAGER", 423, "hive.security.metastore.authenticator.manager", "org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator", "authenticator manager class name to be used in the metastore for authentication. \nThe user defined authenticator should implement interface org.apache.hadoop.hive.ql.security.HiveAuthenticationProvider.");
